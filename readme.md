# Data Science Practicals - Group A  
**Third Year Computer Engineering (2019 Course)**  
**Savitribai Phule Pune University**  

---

## 1. Data Wrangling I

Perform the following operations using Python on any open-source dataset (e.g., `data.csv`):

- Import all the required Python libraries.
- Locate a dataset from the web (e.g., [Kaggle](https://www.kaggle.com)) and provide its description and source URL.
- Load the dataset into a Pandas DataFrame.
- Perform data preprocessing:
  - Check for missing values using `isnull()`
  - Use `describe()` to get statistics
  - Provide variable descriptions, types of variables, and dimensions
- Perform data formatting and normalization:
  - Summarize types of variables and convert them to proper types
- Convert categorical variables into quantitative variables

ðŸ’¡ *Explanation of each operation must be included along with code and output.*

---

## 2. Data Wrangling II

Create a dataset on **academic performance** of students and perform:

- Handle missing values and inconsistencies using suitable techniques
- Detect and handle outliers in numeric variables
- Apply transformation on at least one variable (to change scale, reduce skewness, or linearize relationships)

ðŸ’¡ *Clearly document the purpose and reasoning behind each transformation.*

---

## 3. Descriptive Statistics  
**Measures of Central Tendency and Variability**

- Use any open-source dataset (e.g., `data.csv`)
- Provide summary statistics (mean, median, min, max, std) grouped by a categorical variable
- For the `iris.csv` dataset:
  - Display basic stats (percentiles, mean, std) for `Iris-setosa`, `Iris-versicolor`, and `Iris-virginica`

ðŸ’¡ *Include code, output, and explanation.*

---

## 4. Data Analytics I  
**Linear Regression**

- Create a linear regression model using Python/R
- Dataset: [Boston Housing Dataset](https://www.kaggle.com/c/boston-housing)
- Objective: Predict house prices using features from the dataset (506 samples, 14 features)

---

## 5. Data Analytics II  
**Logistic Regression**

- Perform classification on `Social_Network_Ads.csv` using logistic regression in Python/R
- Compute confusion matrix and calculate:
  - True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN)
  - Accuracy, Error Rate, Precision, Recall

---

## 6. Data Analytics III  
**NaÃ¯ve Bayes Classification**

- Implement simple NaÃ¯ve Bayes classifier using Python/R
- Dataset: `iris.csv`
- Compute confusion matrix and evaluation metrics:
  - TP, FP, TN, FN, Accuracy, Error Rate, Precision, Recall

---

## 7. Text Analytics

- Extract a sample document and apply:
  - Tokenization
  - POS Tagging
  - Stop Words Removal
  - Stemming and Lemmatization
- Create document representation using:
  - Term Frequency (TF)
  - Inverse Document Frequency (IDF)

---

## 8. Data Visualization I  
**Using Titanic Dataset**

- Dataset: Inbuilt `titanic` dataset (891 rows)
- Use **Seaborn** to explore patterns
- Plot histogram to analyze ticket fare distribution

---

## 9. Data Visualization II  
**Box Plot Analysis (Titanic Dataset)**

- Plot a box plot of age grouped by gender (`sex`) and survival status (`survived`)
- Write observations and inferences based on the plot

---

## 10. Data Visualization III  
**Iris Dataset Analysis**

- Dataset: [Iris Dataset](https://archive.ics.uci.edu/ml/datasets/Iris)
- List all features and identify their types (numeric/nominal)
- Create:
  - Histogram for each feature
  - Box plot for each feature
- Compare distributions and identify outliers

---
